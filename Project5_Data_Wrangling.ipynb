{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 5 : Segmenter des clients d'un site e-commerce\n",
    "\n",
    "*Pierre-Eloi Ragetly*\n",
    "\n",
    "Ce projet fait parti du parcours *Data Scientist* d'OpenClassroooms.\n",
    "\n",
    "L'objectif pricipal est de réaliser **une segmentation des clients** d'un site de e-commerce, **une proposition de contrat de maintenance** devra être inclue.\n",
    "\n",
    "Les données mises à notre disposition proviennent du site *kaggle* :\n",
    "https://www.kaggle.com/olistbr/brazilian-ecommerce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie I : Data Wrangling\n",
    "\n",
    "L'objectif de ce notebook est de décrire les opérations de nettoyage nécessaires à l'obtention d'un jeu de données exploitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:25.219674Z",
     "start_time": "2020-08-13T09:00:24.559695Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import usual libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:25.226683Z",
     "start_time": "2020-08-13T09:00:25.221124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change some default parameters of matplotlib using seaborn\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({'axes.titleweight': 'bold'})\n",
    "sns.set(style='ticks')\n",
    "current_palette = sns.color_palette('RdBu')\n",
    "sns.set_palette(current_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Récupération-des-données\" data-toc-modified-id=\"Récupération-des-données-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Récupération des données</a></span></li><li><span><a href=\"#Fusion-des-données\" data-toc-modified-id=\"Fusion-des-données-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Fusion des données</a></span></li><li><span><a href=\"#Ingénierie-des-variables\" data-toc-modified-id=\"Ingénierie-des-variables-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Ingénierie des variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variables-RFM\" data-toc-modified-id=\"Variables-RFM-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Variables RFM</a></span></li><li><span><a href=\"#Nombre-de-produits-par-panier\" data-toc-modified-id=\"Nombre-de-produits-par-panier-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Nombre de produits par panier</a></span></li><li><span><a href=\"#Variables-liées-aux-produits\" data-toc-modified-id=\"Variables-liées-aux-produits-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Variables liées aux produits</a></span></li><li><span><a href=\"#Catégories-des-produits\" data-toc-modified-id=\"Catégories-des-produits-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Catégories des produits</a></span></li><li><span><a href=\"#Variables-liées-aux-commentaires\" data-toc-modified-id=\"Variables-liées-aux-commentaires-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Variables liées aux commentaires</a></span></li><li><span><a href=\"#Moyens-de-paiement\" data-toc-modified-id=\"Moyens-de-paiement-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Moyens de paiement</a></span></li></ul></li><li><span><a href=\"#Mise-à-l'échelle-des-données\" data-toc-modified-id=\"Mise-à-l'échelle-des-données-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Mise à l'échelle des données</a></span></li><li><span><a href=\"#Création-d'un-pipeline\" data-toc-modified-id=\"Création-d'un-pipeline-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Création d'un pipeline</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des données\n",
    "\n",
    "Une fois les données téléchargées, nous pouvons les charger dans un DataFrame en utilisant la librairie **pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:26.504164Z",
     "start_time": "2020-08-13T09:00:25.228810Z"
    }
   },
   "outputs": [],
   "source": [
    "df_customers =  pd.read_csv(\"data/olist_customers_dataset.csv\")\n",
    "df_geolocation = pd.read_csv(\"data/olist_geolocation_dataset.csv\")\n",
    "df_order_items = pd.read_csv(\"data/olist_order_items_dataset.csv\")\n",
    "df_order_payments = pd.read_csv(\"data/olist_order_payments_dataset.csv\")\n",
    "df_order_reviews = pd.read_csv(\"data/olist_order_reviews_dataset.csv\")\n",
    "df_orders = pd.read_csv(\"data/olist_orders_dataset.csv\")\n",
    "df_products = pd.read_csv(\"data/olist_products_dataset.csv\")\n",
    "df_sellers = pd.read_csv(\"data/olist_sellers_dataset.csv\")\n",
    "df_translation = pd.read_csv(\"data/product_category_name_translation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons ce qui est contenu dans chaque DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:26.523164Z",
     "start_time": "2020-08-13T09:00:26.505934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:26.594531Z",
     "start_time": "2020-08-13T09:00:26.524703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000163 entries, 0 to 1000162\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   geolocation_zip_code_prefix  1000163 non-null  int64  \n",
      " 1   geolocation_lat              1000163 non-null  float64\n",
      " 2   geolocation_lng              1000163 non-null  float64\n",
      " 3   geolocation_city             1000163 non-null  object \n",
      " 4   geolocation_state            1000163 non-null  object \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 38.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_geolocation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:26.614620Z",
     "start_time": "2020-08-13T09:00:26.596106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   order_id             112650 non-null  object \n",
      " 1   order_item_id        112650 non-null  int64  \n",
      " 2   product_id           112650 non-null  object \n",
      " 3   seller_id            112650 non-null  object \n",
      " 4   shipping_limit_date  112650 non-null  object \n",
      " 5   price                112650 non-null  float64\n",
      " 6   freight_value        112650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_order_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:26.628025Z",
     "start_time": "2020-08-13T09:00:26.616056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103886 entries, 0 to 103885\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              103886 non-null  object \n",
      " 1   payment_sequential    103886 non-null  int64  \n",
      " 2   payment_type          103886 non-null  object \n",
      " 3   payment_installments  103886 non-null  int64  \n",
      " 4   payment_value         103886 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_order_payments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:26.654346Z",
     "start_time": "2020-08-13T09:00:26.630895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   review_id                100000 non-null  object\n",
      " 1   order_id                 100000 non-null  object\n",
      " 2   review_score             100000 non-null  int64 \n",
      " 3   review_comment_title     11715 non-null   object\n",
      " 4   review_comment_message   41753 non-null   object\n",
      " 5   review_creation_date     100000 non-null  object\n",
      " 6   review_answer_timestamp  100000 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_order_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:26.683827Z",
     "start_time": "2020-08-13T09:00:26.656491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_approved_at              99281 non-null  object\n",
      " 5   order_delivered_carrier_date   97658 non-null  object\n",
      " 6   order_delivered_customer_date  96476 non-null  object\n",
      " 7   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:26.692978Z",
     "start_time": "2020-08-13T09:00:26.685116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:26.700057Z",
     "start_time": "2020-08-13T09:00:26.694268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 96.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sellers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:26.706348Z",
     "start_time": "2020-08-13T09:00:26.701545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71 entries, 0 to 70\n",
      "Data columns (total 2 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   product_category_name          71 non-null     object\n",
      " 1   product_category_name_english  71 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_translation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons noter plusieurs choses :\n",
    "1. Il va falloir fusionner ces tables afin de créer une table unique\n",
    "2. La table geolocation n'apporte rien de plus que la table *customers*\n",
    "3. Beaucoup de données redondantes\n",
    "4. Les tables contiennent très peu de données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de commencer à nettoyer les données, nous allons commencer par fusionner les données afin d'obtenir une table unique. Ce qui sera bien plus pratique pour manipuler les données.  \n",
    "Nous en profiterons pour convertir les dates dans un format date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:26.713301Z",
     "start_time": "2020-08-13T09:00:26.707927Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_data(list_df):\n",
    "    \"\"\"Function merging different DataFrames to get a unique one.\n",
    "     Parameters:\n",
    "    list_df: list object\n",
    "        a list with all dataframes to be merged\n",
    "    -----------\n",
    "    Return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    df = (pd.merge(left=list_df[0], right=list_df[1],\n",
    "                   how=\"left\", on=\"customer_id\")\n",
    "            .merge(right=list_df[2], how=\"left\",\n",
    "                   on=\"order_id\", copy=False)\n",
    "            .merge(right=list_df[3], how=\"left\",\n",
    "                   on=\"product_id\", copy=False)\n",
    "            .merge(right=list_df[4], how=\"left\",\n",
    "                   on=\"order_id\", copy=False)\n",
    "            .merge(right=list_df[5], how=\"left\",\n",
    "                   on=\"order_id\", copy=False)\n",
    "            .merge(right=list_df[6], how=\"left\",\n",
    "                   on=\"product_category_name\", copy=False))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:27.281156Z",
     "start_time": "2020-08-13T09:00:26.714667Z"
    }
   },
   "outputs": [],
   "source": [
    "list_df = [df_customers,\n",
    "           df_orders,\n",
    "           df_order_items,\n",
    "           df_products,\n",
    "           df_order_payments,\n",
    "           df_order_reviews,\n",
    "           df_translation]\n",
    "\n",
    "df = merge_data(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:27.285530Z",
     "start_time": "2020-08-13T09:00:27.282585Z"
    }
   },
   "outputs": [],
   "source": [
    "def date_monthly(data, feat_to_convert):\n",
    "    \"\"\"Function converting data features into a monthy basis date.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    feat_to_convert: list of strings\n",
    "        list holding the name of features to convert\n",
    "    -----------\n",
    "    Return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    for c in feat_to_convert:\n",
    "        data[c] = pd.to_datetime(data[c]).dt.date\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:27.434868Z",
     "start_time": "2020-08-13T09:00:27.287126Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_to_convert = [\"order_purchase_timestamp\",\n",
    "                   \"review_creation_date\",\n",
    "                   \"review_answer_timestamp\"]\n",
    "df = date_monthly(df, feat_to_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:30.260713Z",
     "start_time": "2020-08-13T09:00:27.436235Z"
    }
   },
   "outputs": [],
   "source": [
    "# export in csv format the merge dataset\n",
    "df.to_csv(\"data/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingénierie des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon nombre des variables ne sont pas exploitables en l'état, il va falloir les transformer avant de penser à les utiliser pour faire tourner des modèles de partionnement.\n",
    "\n",
    "De plus, ayant pour but de faire une segmentation des clients il va nous falloir regrouper les données par client. Dans la base de donnée, un client unique est assigné à chaque transaction. Ainsi, un client ayant effectué plusieurs transactions se verra attribuer plusieurs *customer_id*. C'est pourquoi nous avons aussi accès à la variable *customer_unique_id*. C'est cette dernière que nous utiliserons pour regrouper les données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables RFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode de segmentation de clients la plus utilisée est le calcul d'un score RFM (Recency, Frequency, Monetary Value). Ce score consiste à donner une note entre 1 et 10 pour trois variables :\n",
    "- récence : maximum entre \"10 - le nombre de mois écoulés entre aujourd'hui et le dernier achat effectué\" et 1\n",
    "- fréquence : maximum entre \"le nombre d'achats effectués (avec une limite de 10) sur une période (en général 12 mois) et 1\".\n",
    "- achat : totalité des achats sur une période de temps ou montant du panier moyen. Ici nous prendrons le panier moyen, et attribuerons comme note le numéro du décile.\n",
    "\n",
    "Le score est obtenu en additionnant ces trois notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:30.269720Z",
     "start_time": "2020-08-13T09:00:30.262391Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_rfm(data, m_mean=False):\n",
    "    \"\"\"Function to get the three RFM features,\n",
    "    commonly used in database marketing.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    m_mean: bool, default False\n",
    "        to get the mean and not the total for the monetary value\n",
    "    -----------\n",
    "    Return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    r_feature = \"order_purchase_timestamp\"\n",
    "    f_feature = \"order_id\"\n",
    "    m_feature = \"price\"\n",
    "    # Set a reference date\n",
    "    date_ref = data[r_feature].max()\n",
    "    # get the Recency\n",
    "    recency = (data.groupby(\"customer_unique_id\")\n",
    "                   .order_purchase_timestamp\n",
    "                   .max())\n",
    "    recency = 10 - (date_ref-recency)/np.timedelta64(1, 'M')\n",
    "    recency = (recency.round()\n",
    "                      .fillna(0)\n",
    "                      .where(recency>1, other=1))\n",
    "    # get the Monetary_value\n",
    "    monetary = (data.groupby(\"customer_unique_id\")\n",
    "                    .price\n",
    "                    .sum()\n",
    "                    .fillna(0))\n",
    "    if m_mean:\n",
    "        monetary /= (data.groupby(\"customer_unique_id\")\n",
    "                         .order_id\n",
    "                         .nunique())\n",
    "    monetary = (pd.qcut(monetary, q=10,\n",
    "                        labels=np.linspace(1, 10, 10))\n",
    "                  .astype(int))\n",
    "    # get the Frequency\n",
    "    frequency = (data.groupby(\"customer_unique_id\")\n",
    "                     .order_id\n",
    "                     .nunique())\n",
    "    frequency = (frequency.fillna(0)\n",
    "                          .where(frequency>0, other=1)\n",
    "                          .where(frequency<10, other=10))\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\"Recency\": recency,\n",
    "                       \"Frequency\": frequency,\n",
    "                       \"Monetary_value\": monetary},\n",
    "                      index=recency.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:38.639498Z",
     "start_time": "2020-08-13T09:00:30.271517Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_rfm(df, m_mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre de produits par panier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En plus du RFM, il peut être utilé de connaître le nombre moyen de produits contenus dans le panier. Cela permettrait notamment de distinguer les grossistes des particuliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:38.643674Z",
     "start_time": "2020-08-13T09:00:38.640725Z"
    }
   },
   "outputs": [],
   "source": [
    "def products_per_order(data):\n",
    "    \"\"\"Function to get the average number\n",
    "    of products per order.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    -----------\n",
    "    Return: Series\n",
    "        the pandas object holding data\n",
    "    \"\"\"\n",
    "    s = data.groupby(\"customer_unique_id\")[\"product_id\"].count()/ \\\n",
    "        data.groupby(\"customer_unique_id\")[\"order_id\"].nunique()\n",
    "    return s.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:38.916540Z",
     "start_time": "2020-08-13T09:00:38.645368Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"order_n_products\"] = products_per_order(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables liées aux produits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant essayer de déterminer le produit type acheté par chaque client en ajoutant trois variables à notre DataFrame :\n",
    "- prix\n",
    "- longeur de la description\n",
    "- frais de port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:39.007295Z",
     "start_time": "2020-08-13T09:00:38.917782Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def product_type(data):\n",
    "    \"\"\"Function to get the type product for each customer.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    -----------\n",
    "    Return: 1d Array\n",
    "        the numpy object holding data\n",
    "    \"\"\"\n",
    "    # create a dataframe will all required features\n",
    "    features = [\"price\",\n",
    "                \"product_description_lenght\",\n",
    "                \"freight_value\"]\n",
    "    \n",
    "    df = data.groupby(\"customer_unique_id\")[features].mean()\n",
    "    # Impute missing data by the mean\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X = imp_mean.fit_transform(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:39.125016Z",
     "start_time": "2020-08-13T09:00:39.011640Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"product_type\"] = product_type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catégories des produits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant créer une variable par catégorie de produit que nous renseignerons par la proportion de produits de cette catégorie acheté par chaque client. C'est la version anglaise des noms de catégorie qui sera utilisé.\n",
    "\n",
    "Puis nous réaliserons une ACP de manière à voir si nous pouvons réduire ce nombre de catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:39.132882Z",
     "start_time": "2020-08-13T09:00:39.127103Z"
    }
   },
   "outputs": [],
   "source": [
    "def product_category(data):\n",
    "    \"\"\"Function to get the product category for each customer.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    -----------\n",
    "    Return: 1d Array\n",
    "        the numpy object holding data\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    # Create a feature by category\n",
    "    list_products_cat = df[\"product_category_name_english\"].unique().tolist()\n",
    "    for c in list_products_cat:\n",
    "        cond = df[\"product_category_name_english\"]==c\n",
    "        df[c] = 1\n",
    "        df[c] = df[c].where(cond, 0)\n",
    "    # Group all data by customer\n",
    "    df = df.groupby(\"customer_unique_id\")[list_products_cat].sum()\n",
    "    # Calculate the proportions\n",
    "    for c in list_products_cat:\n",
    "        df[c] /= (data.groupby(\"customer_unique_id\")\n",
    "                      .product_id\n",
    "                      .count())\n",
    "    # Impute missing data and normalize data\n",
    "    X = df.fillna(0).values\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    # Realize the PCA\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(X_scaled)\n",
    "    print(\"The percentage of variance explained by the first component is:\\n \\\n",
    "          {}\".format(pca.explained_variance_ratio_))\n",
    "    return pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:49.198712Z",
     "start_time": "2020-08-13T09:00:39.134178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of variance explained by the first component is:\n",
      "           [0.01486604]\n"
     ]
    }
   ],
   "source": [
    "data[\"product_category\"] = product_category(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous constatons que la proportion de la variance expliquée par le première composante est trés faible. Ceci nous indique que chaque variable est fortement décorrélée des autres et donc que l'ACP n'arrive pas à les regrouper. Dans ces conditions, l'ACP nous sera d'aucune utilité.\n",
    "\n",
    "Nous pourrions envisager de ne garder que les catégories les plus achetées, mais se poserait alors la question de combien de catégorie garder. Les résultats de notre clustering seront fort probablement différents selon que nous décidions de garder X ou Y variables, et donc biaiserait les résultats.\n",
    "\n",
    "Pour ces raisons, nous n'utiliserons pas les catégories pour effectuer clustering. En revanche, nous les utiliserons une fois le partitionnement effectué afin de caractériser les clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables liées aux commentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous traiterons maintenant les variables liées aux commentaires. Pour chaque client, nous calculerons un score (entre 1 et 10) pour les variables suivantes :\n",
    "- temps de réponse moyen\n",
    "- nombre de commentaires\n",
    "- score moyen des commentaires\n",
    "\n",
    "Puis nous additionnerons ces 3 scores, et diviserons le résultat par 3 pour avoir une note finale entre 1 et 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:49.207368Z",
     "start_time": "2020-08-13T09:00:49.200464Z"
    }
   },
   "outputs": [],
   "source": [
    "def review_score(data):\n",
    "    \"\"\"Function to get a score of the reviews\n",
    "    based on three features:\n",
    "    - the satisfaction survey answer timedelta\n",
    "    - number of reviews per customer\n",
    "    - the mark given by the review\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    -----------\n",
    "    Return: Series\n",
    "        the pandas object holding data\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    # get the survey answer timedelta in days\n",
    "    df[\"review_answer_timedelta\"] = df[\"review_answer_timestamp\"]\n",
    "    df[\"review_answer_timedelta\"] -= df[\"review_creation_date\"]\n",
    "    df[\"review_answer_timedelta\"] /= np.timedelta64(1, 'D')\n",
    "    review_timedelta = (df.groupby(\"customer_unique_id\")\n",
    "                          .review_answer_timedelta\n",
    "                          .mean())\n",
    "    review_timedelta = 10 - review_timedelta\n",
    "    review_timedelta = (review_timedelta.round()\n",
    "                                        .fillna(0)\n",
    "                                        .where(review_timedelta>1,\n",
    "                                               other=1))\n",
    "    # get the number of review per customer\n",
    "    review_n = (df.groupby(\"customer_unique_id\")\n",
    "                  .review_id\n",
    "                  .count())\n",
    "    review_n = (review_n.fillna(0)\n",
    "                        .where(review_n>0, other=1)\n",
    "                        .where(review_n<10, other=10))\n",
    "    # get the review mark\n",
    "    review_mark = (df.groupby(\"customer_unique_id\")\n",
    "                     .review_score\n",
    "                     .mean())\n",
    "    review_mark *=2\n",
    "    review_mark = (review_mark.fillna(review_mark.mean())\n",
    "                              .round())\n",
    "    # get the score\n",
    "    review = review_timedelta + review_n + review_mark\n",
    "    review /= 3\n",
    "    return review.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:50.082085Z",
     "start_time": "2020-08-13T09:00:49.208849Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"review\"] = review_score(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moyens de paiement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il pourrait être utile de voir le moyen de paiement privilégié par chaque client. Pour cela nous allons créer une variable par moyen de paiement possible, et nous renseignerons la proportion du montant total payé par ce moyen de paiement.\n",
    "\n",
    "Commençons par vérifier les types de paiement possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:50.095921Z",
     "start_time": "2020-08-13T09:00:50.083500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_card    87784\n",
       "boleto         23190\n",
       "voucher         6465\n",
       "debit_card      1706\n",
       "not_defined        3\n",
       "Name: payment_type, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.payment_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons que les trois dernière modalités regroupent moins de 10% des transactions, nous allons les regrouper sous la catégorie *other_payment*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:50.101769Z",
     "start_time": "2020-08-13T09:00:50.097197Z"
    }
   },
   "outputs": [],
   "source": [
    "def payment_type(data):\n",
    "    \"\"\"Function to get the type of payment used by each customer.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    -----------\n",
    "    Return: tuple\n",
    "        * The list of the payment_types\n",
    "        * the numpy object holding data\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    df.payment_type.where(df.payment_type.isin([\"credit_card\", \"boleto\"]),\n",
    "                          \"other_payment\", inplace=True)\n",
    "    # Create a feature by type of payment\n",
    "    list_payment_type = (df.payment_type\n",
    "                           .unique()\n",
    "                           .tolist())\n",
    "    for c in list_payment_type:\n",
    "        cond = df[\"payment_type\"]==c\n",
    "        df[c] = df[\"payment_value\"]\n",
    "        df[c] = df[c].where(cond, 0)\n",
    "    # Group all data by customer\n",
    "    df = df.groupby(\"customer_unique_id\")[list_payment_type].sum()\n",
    "    # Calculate the proportions\n",
    "    for c in list_payment_type:\n",
    "        df[c] /= (data.groupby(\"customer_unique_id\")\n",
    "                      .payment_value\n",
    "                      .sum())\n",
    "    return list_payment_type, df.fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:50.629903Z",
     "start_time": "2020-08-13T09:00:50.102970Z"
    }
   },
   "outputs": [],
   "source": [
    "list_payment, payment_array = payment_type(df)\n",
    "for i, c in enumerate(list_payment):\n",
    "    data[c] = payment_array[:, i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise à l'échelle des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer une fonction pour changer l'échelle des données. Nous commencerons par normaliser les données. Puis, nous changerons le poids des variables *RFM* de manière à ce que ces trois dernières représentent la moitié du poids total des variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:50.635492Z",
     "start_time": "2020-08-13T09:00:50.631648Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_data(data):\n",
    "    \"\"\"Function to scale data by:\n",
    "    1) removing the mean and scaling to unit variance.\n",
    "    2) Increasing the weigh of RFM features\n",
    "    -----------\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    -----------\n",
    "    Return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    rfm_feat = [\"Recency\", \"Frequency\", \"Monetary_value\"]\n",
    "    df = data.copy()\n",
    "    n = data.columns.size\n",
    "    weight = (n-3) / 3\n",
    "    X = data.values\n",
    "    std_scaler = StandardScaler()\n",
    "    X_scaled = std_scaler.fit_transform(X)\n",
    "    df.loc[:, :] = X_scaled\n",
    "    df.loc[:, rfm_feat] *= weight\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour finir nous créerons un pipeline permettant de faire toutes ces transformations à la suite. Nous ajouterons en amont du pipeline une fonction permettant de filtrer les données en ne gardant que les transactions antérieures à une date de référence qui sera entrée en paramètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:50.640550Z",
     "start_time": "2020-08-13T09:00:50.637698Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_filter(data, ref_date):\n",
    "    \"\"\"Function to filter data by keeping only\n",
    "    the orders purchased prior to a reference data\n",
    "    entered in parameter.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    ref_date: datetime object\n",
    "        the reference date to be used to filter data\n",
    "    -----------\n",
    "    Return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    return data[data.order_purchase_timestamp<=ref_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T09:00:50.647611Z",
     "start_time": "2020-08-13T09:00:50.642415Z"
    }
   },
   "outputs": [],
   "source": [
    "def wrangling_pipeline(data, ref_date=None, m_mean=False):\n",
    "    \"\"\"pipeline to carry out all functions of data wrangling.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    ref_date: datetime object\n",
    "        the reference date to be used to filter data    \n",
    "    m_mean: bool, default False\n",
    "        to get the mean and not the total for the monetary value\n",
    "    -----------\n",
    "    Return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    if not ref_date:\n",
    "        ref_date = data.order_purchase_timestamp.max()\n",
    "    df = data_filter(data, ref_date=ref_date)\n",
    "    df = get_rfm(df, m_mean=m_mean)\n",
    "    df[\"order_n_products\"] = products_per_order(data)\n",
    "    df[\"product_type\"] = product_type(data)\n",
    "    df[\"product_category\"] = product_category(data)\n",
    "    df[\"review\"] = review_score(data)\n",
    "    list_payment, payment_array = payment_type(df)\n",
    "    for i, c in enumerate(list_payment):\n",
    "        df[c] = payment_array[:, i]\n",
    "    return scale_data(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
