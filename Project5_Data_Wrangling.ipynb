{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 5 : Segmenter des clients d'un site e-commerce\n",
    "\n",
    "*Pierre-Eloi Ragetly*\n",
    "\n",
    "Ce projet fait parti du parcours *Data Scientist* d'OpenClassroooms.\n",
    "\n",
    "L'objectif pricipal est de réaliser **une segmentation des clients** d'un site de e-commerce, **une proposition de contrat de maintenance** devra être inclue.\n",
    "\n",
    "Les données mises à notre disposition proviennent du site *kaggle* :\n",
    "https://www.kaggle.com/olistbr/brazilian-ecommerce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie I : Data Wrangling\n",
    "\n",
    "L'objectif de ce notebook est de décrire les opérations de nettoyage nécessaires à l'obtention d'un jeu de données exploitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:52.311261Z",
     "start_time": "2020-08-03T16:26:52.307501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import usual libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:52.320185Z",
     "start_time": "2020-08-03T16:26:52.313064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change some default parameters of matplotlib using seaborn\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({'axes.titleweight': 'bold'})\n",
    "sns.set(style='ticks')\n",
    "current_palette = sns.color_palette('RdBu')\n",
    "sns.set_palette(current_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Récupération-des-données\" data-toc-modified-id=\"Récupération-des-données-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Récupération des données</a></span></li><li><span><a href=\"#Fusion-des-données\" data-toc-modified-id=\"Fusion-des-données-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Fusion des données</a></span></li><li><span><a href=\"#Ingénierie-des-variables\" data-toc-modified-id=\"Ingénierie-des-variables-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Ingénierie des variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variables-RFM\" data-toc-modified-id=\"Variables-RFM-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Variables RFM</a></span></li><li><span><a href=\"#Nombre-de-produits-par-panier\" data-toc-modified-id=\"Nombre-de-produits-par-panier-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Nombre de produits par panier</a></span></li><li><span><a href=\"#Variables-liées-aux-produits\" data-toc-modified-id=\"Variables-liées-aux-produits-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Variables liées aux produits</a></span></li><li><span><a href=\"#Catégories-des-produits\" data-toc-modified-id=\"Catégories-des-produits-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Catégories des produits</a></span></li><li><span><a href=\"#Variables-liées-aux-commentaires\" data-toc-modified-id=\"Variables-liées-aux-commentaires-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Variables liées aux commentaires</a></span></li><li><span><a href=\"#Moyens-de-paiement\" data-toc-modified-id=\"Moyens-de-paiement-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Moyens de paiement</a></span></li><li><span><a href=\"#Les-plus-gros-vendeurs\" data-toc-modified-id=\"Les-plus-gros-vendeurs-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Les plus gros vendeurs</a></span></li><li><span><a href=\"#États\" data-toc-modified-id=\"États-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>États</a></span></li><li><span><a href=\"#Fusion-des-pivot-tables\" data-toc-modified-id=\"Fusion-des-pivot-tables-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>Fusion des pivot tables</a></span></li></ul></li><li><span><a href=\"#Export-des-données\" data-toc-modified-id=\"Export-des-données-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Export des données</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des données\n",
    "\n",
    "Une fois les données téléchargées, nous pouvons les charger dans un DataFrame en utilisant la librairie **pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:53.627133Z",
     "start_time": "2020-08-03T16:26:52.322426Z"
    }
   },
   "outputs": [],
   "source": [
    "df_customers =  pd.read_csv(\"data/olist_customers_dataset.csv\")\n",
    "df_geolocation = pd.read_csv(\"data/olist_geolocation_dataset.csv\")\n",
    "df_order_items = pd.read_csv(\"data/olist_order_items_dataset.csv\")\n",
    "df_order_payments = pd.read_csv(\"data/olist_order_payments_dataset.csv\")\n",
    "df_order_reviews = pd.read_csv(\"data/olist_order_reviews_dataset.csv\")\n",
    "df_orders = pd.read_csv(\"data/olist_orders_dataset.csv\")\n",
    "df_products = pd.read_csv(\"data/olist_products_dataset.csv\")\n",
    "df_sellers = pd.read_csv(\"data/olist_sellers_dataset.csv\")\n",
    "df_translation = pd.read_csv(\"data/product_category_name_translation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons ce qui est contenu dans chaque DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:53.646523Z",
     "start_time": "2020-08-03T16:26:53.628981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:53.714736Z",
     "start_time": "2020-08-03T16:26:53.648169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000163 entries, 0 to 1000162\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   geolocation_zip_code_prefix  1000163 non-null  int64  \n",
      " 1   geolocation_lat              1000163 non-null  float64\n",
      " 2   geolocation_lng              1000163 non-null  float64\n",
      " 3   geolocation_city             1000163 non-null  object \n",
      " 4   geolocation_state            1000163 non-null  object \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 38.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_geolocation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:53.734409Z",
     "start_time": "2020-08-03T16:26:53.716065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   order_id             112650 non-null  object \n",
      " 1   order_item_id        112650 non-null  int64  \n",
      " 2   product_id           112650 non-null  object \n",
      " 3   seller_id            112650 non-null  object \n",
      " 4   shipping_limit_date  112650 non-null  object \n",
      " 5   price                112650 non-null  float64\n",
      " 6   freight_value        112650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_order_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:53.747604Z",
     "start_time": "2020-08-03T16:26:53.735737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103886 entries, 0 to 103885\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              103886 non-null  object \n",
      " 1   payment_sequential    103886 non-null  int64  \n",
      " 2   payment_type          103886 non-null  object \n",
      " 3   payment_installments  103886 non-null  int64  \n",
      " 4   payment_value         103886 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_order_payments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:53.773899Z",
     "start_time": "2020-08-03T16:26:53.750520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   review_id                100000 non-null  object\n",
      " 1   order_id                 100000 non-null  object\n",
      " 2   review_score             100000 non-null  int64 \n",
      " 3   review_comment_title     11715 non-null   object\n",
      " 4   review_comment_message   41753 non-null   object\n",
      " 5   review_creation_date     100000 non-null  object\n",
      " 6   review_answer_timestamp  100000 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_order_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:53.803033Z",
     "start_time": "2020-08-03T16:26:53.776367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   order_id                       99441 non-null  object\n",
      " 1   customer_id                    99441 non-null  object\n",
      " 2   order_status                   99441 non-null  object\n",
      " 3   order_purchase_timestamp       99441 non-null  object\n",
      " 4   order_approved_at              99281 non-null  object\n",
      " 5   order_delivered_carrier_date   97658 non-null  object\n",
      " 6   order_delivered_customer_date  96476 non-null  object\n",
      " 7   order_estimated_delivery_date  99441 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:53.813024Z",
     "start_time": "2020-08-03T16:26:53.804452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:53.819688Z",
     "start_time": "2020-08-03T16:26:53.814301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 96.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sellers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:53.825500Z",
     "start_time": "2020-08-03T16:26:53.821253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71 entries, 0 to 70\n",
      "Data columns (total 2 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   product_category_name          71 non-null     object\n",
      " 1   product_category_name_english  71 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_translation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons noter plusieurs choses :\n",
    "1. Il va falloir fusionner ces tables afin de créer une table unique\n",
    "2. La table geolocation n'apporte rien de plus que la table *customers*\n",
    "3. Beaucoup de données redondantes\n",
    "4. Les tables contiennent très peu de données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de commencer à nettoyer les données, nous allons commencer par fusionner les données afin d'obtenir une table unique. Ce qui sera bien plus pratique pour manipuler les données.  \n",
    "Nous en profiterons pour convertir les dates en utilant une base mensuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:53.831486Z",
     "start_time": "2020-08-03T16:26:53.826965Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_data(list_df):\n",
    "    \"\"\"Function merging different DataFrames to get a unique one.\n",
    "     Parameters:\n",
    "    list_df: list object\n",
    "        a list with all dataframes to be merged\n",
    "    -----------\n",
    "    Return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    df = (pd.merge(left=list_df[0], right=list_df[1],\n",
    "                   how=\"left\", on=\"customer_id\")\n",
    "            .merge(right=list_df[2], how=\"left\",\n",
    "                   on=\"order_id\", copy=False)\n",
    "            .merge(right=list_df[3], how=\"left\",\n",
    "                   on=\"product_id\", copy=False)\n",
    "            .merge(right=list_df[4], how=\"left\",\n",
    "                   on=\"order_id\", copy=False)\n",
    "            .merge(right=list_df[5], how=\"left\",\n",
    "                   on=\"order_id\", copy=False))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:54.344193Z",
     "start_time": "2020-08-03T16:26:53.832786Z"
    }
   },
   "outputs": [],
   "source": [
    "list_df = [df_customers,\n",
    "           df_orders,\n",
    "           df_order_items,\n",
    "           df_products,\n",
    "           df_order_payments,\n",
    "           df_order_reviews]\n",
    "\n",
    "df = merge_data(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:54.348164Z",
     "start_time": "2020-08-03T16:26:54.345439Z"
    }
   },
   "outputs": [],
   "source": [
    "def date_monthly(data, feat_to_convert):\n",
    "    \"\"\"Function converting data features into a monthy basis date.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    feat_to_convert: list of strings\n",
    "        list holding the name of features to convert\n",
    "    -----------\n",
    "    Return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    for c in feat_to_convert:\n",
    "        data[c] = pd.to_datetime(data[c]).dt.date\n",
    "        #data[c] = pd.to_datetime(data[c].dt.strftime('%Y-%m'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:54.408424Z",
     "start_time": "2020-08-03T16:26:54.349847Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_to_convert = [\"order_purchase_timestamp\"]\n",
    "df = date_monthly(df, feat_to_convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingénierie des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon nombre des variables ne sont pas exploitables en l'état, il va falloir les transformer avant de penser à les utiliser pour faire tourner des modèles de partionnement.\n",
    "\n",
    "De plus, ayant pour but de faire une segmentation des clients il va nous falloir regrouper les données par client. Dans la base de donnée, un client unique est assigné à chaque transaction. Ainsi, un client ayant effectué plusieurs transactions se verra attribuer plusieurs *customer_id*. C'est pourquoi nous avons aussi accès à la variable *customer_unique_id*. C'est cette dernière que nous utiliserons pour regrouper les données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables RFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode de segmentation de clients la plus utilisée est le calcul d'un score RFM (Recency, Frequency, Monetary Value). Ce score consiste à donner une note entre 1 et 10 pour trois variables :\n",
    "- récence : maximum entre \"10 - le nombre de mois écoulés entre aujourd'hui et le dernier achat effectué\" et 1\n",
    "- fréquence : maximum entre \"le nombre d'achats effectués (avec une limite de 10) sur une période (en général 12 mois) et 1\".\n",
    "- achat : totalité des achats sur une période de temps ou montant du panier moyen. Ici nous prendrons le panier moyen, et attribuerons comme note le numéro du décile.\n",
    "\n",
    "Le score est obtenu en additionnant ces trois notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:26:54.415508Z",
     "start_time": "2020-08-03T16:26:54.409603Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_rfm(data, m_mean=False):\n",
    "    \"\"\"Function to get the three RFM features,\n",
    "    commonly used in database marketing.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    m_mean: bool, default False\n",
    "        to get the mean and not the total for the monetary value\n",
    "    -----------\n",
    "    Return:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    r_feature = \"order_purchase_timestamp\"\n",
    "    f_feature = \"order_id\"\n",
    "    m_feature = \"price\"\n",
    "    # Set a reference date\n",
    "    date_ref = data[r_feature].max()\n",
    "    # get the Recency\n",
    "    recency = (data.groupby(\"customer_unique_id\")\n",
    "                   .order_purchase_timestamp\n",
    "                   .max())\n",
    "    recency = 10 - (date_ref-recency)/np.timedelta64(1, 'M')\n",
    "    recency = (recency.round()\n",
    "                      .fillna(0)\n",
    "                      .where(recency>1, other=1))\n",
    "    # get the Monetary_value\n",
    "    monetary = (data.groupby(\"customer_unique_id\")\n",
    "                    .price\n",
    "                    .sum()\n",
    "                    .fillna(0))\n",
    "    if m_mean:\n",
    "        monetary /= (data.groupby(\"customer_unique_id\")\n",
    "                         .order_id\n",
    "                         .nunique())\n",
    "    monetary = (pd.qcut(monetary, q=10,\n",
    "                        labels=np.linspace(1, 10, 10))\n",
    "                  .astype(int))\n",
    "    # get the Frequency\n",
    "    frequency = (data.groupby(\"customer_unique_id\")\n",
    "                     .order_id\n",
    "                     .nunique())\n",
    "    frequency = (frequency.fillna(0)\n",
    "                          .where(frequency>0, other=1)\n",
    "                          .where(frequency<10, other=10))\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\"Recency\": recency,\n",
    "                       \"Frequency\": frequency,\n",
    "                       \"Monetary_value\": monetary},\n",
    "                      index=recency.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:27:02.728492Z",
     "start_time": "2020-08-03T16:26:54.417124Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_rfm(df, m_mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Nombre de produits par panier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "En plus du RFM, il peut être utilé de connaître le nombre moyen de produits contenus dans le panier. Cela permettrait notamment de distinguer les grossistes des particuliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:27:02.733285Z",
     "start_time": "2020-08-03T16:27:02.730024Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def products_per_order(data):\n",
    "    \"\"\"Function to get the average number\n",
    "    of products per order.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    -----------\n",
    "    Return: Series\n",
    "        the pandas object holding data\n",
    "    \"\"\"\n",
    "    s = data.groupby(\"customer_unique_id\")[\"product_id\"].count()/ \\\n",
    "        data.groupby(\"customer_unique_id\")[\"order_id\"].nunique()\n",
    "    return s.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:27:02.996731Z",
     "start_time": "2020-08-03T16:27:02.735023Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data[\"order_n_products\"] = products_per_order(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables liées aux produits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous traiterons ensuite les variables liées aux produits. Pour commencer nous allons déterminer le produit type acheté par chaque client, pour cela nous utiliserons les variables suivantes :\n",
    "- prix\n",
    "- nombre de photos\n",
    "- longeur de la description\n",
    "- frais de port\n",
    "\n",
    "Puis nous effectuerons une ACP en ne gardant que la composante principale, de manière à réduire ces 7 variables à une seule tout en minimisante la perte d'information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T17:05:30.787758Z",
     "start_time": "2020-08-03T17:05:30.783335Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def product_type(data):\n",
    "    \"\"\"Function to get the type product for each customer.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    -----------\n",
    "    Return: 1d Array\n",
    "        the numpy object holding data\n",
    "    \"\"\"\n",
    "    # create a dataframe will all required features\n",
    "    features = [\"price\",\n",
    "                \"product_photos_qty\",\n",
    "                \"product_description_lenght\",\n",
    "                \"freight_value\"]\n",
    "    \n",
    "    df = data.groupby(\"customer_unique_id\")[features].mean()\n",
    "    # Impute missing data and normalize data\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X = imp_mean.fit_transform(df.values)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    # Realize the PCA\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(X_scaled)\n",
    "    print(\"The percentage of variance explained by the first component is:\\n \\\n",
    "          {}\".format(pca.explained_variance_ratio_))\n",
    "    print(features)\n",
    "    print(\"The components of the first component in the feature space are:\\n \\\n",
    "          {}\".format(pca.components_))\n",
    "    return pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T17:05:32.256906Z",
     "start_time": "2020-08-03T17:05:32.098860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of variance explained by the first component is:\n",
      "           [0.38294454]\n",
      "['price', 'product_photos_qty', 'product_description_lenght', 'freight_value']\n",
      "The components of the first component in the feature space are:\n",
      "           [[0.65882427 0.17940931 0.4014285  0.61042448]]\n"
     ]
    }
   ],
   "source": [
    "data[\"type_product\"] = product_type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catégories des produits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant créer une variable par catégorie de produit que nous renseignerons par la proportion de produits de cette catégorie acheté par chaque client.\n",
    "\n",
    "Puis nous réaliserons une ACP de manière à réduire le nombre de variables à une."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T17:00:43.838641Z",
     "start_time": "2020-08-03T17:00:43.833448Z"
    }
   },
   "outputs": [],
   "source": [
    "def product_category(data):\n",
    "    \"\"\"Function to get the product category for each customer.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    -----------\n",
    "    Return: 1d Array\n",
    "        the numpy object holding data\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    # Create a feature by category\n",
    "    list_products_cat = df[\"product_category_name\"].unique().tolist()\n",
    "    for c in list_products_cat:\n",
    "        cond = df[\"product_category_name\"]==c\n",
    "        df[c] = 1\n",
    "        df[c] = df[c].where(cond, 0)\n",
    "    # Group all data by customer\n",
    "    df = df.groupby(\"customer_unique_id\")[list_products_cat].sum()\n",
    "    # Calculate the proportions\n",
    "    for c in list_products_cat:\n",
    "        df[c] /= (data.groupby(\"customer_unique_id\")\n",
    "                      .product_id\n",
    "                      .count())\n",
    "    # Impute missing data and normalize data\n",
    "    X = df.fillna(0).values\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    # Realize the PCA\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(X_scaled)\n",
    "    print(\"The percentage of variance explained by the first component is:\\n \\\n",
    "          {}\".format(pca.explained_variance_ratio_))\n",
    "    return pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T17:00:54.722574Z",
     "start_time": "2020-08-03T17:00:44.789189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of variance explained by the first component is:\n",
      "           [0.01446243]\n"
     ]
    }
   ],
   "source": [
    "data[\"product_category\"] = product_category(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Variables liées aux commentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nous traiterons maintenant les variables liées aux commentaires. Pour chaque client, nous calculerons les variables suivantes :\n",
    "- nombre moyens de commentaires par transactions\n",
    "- score moyen\n",
    "- temps de réponse moyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T07:19:13.324054Z",
     "start_time": "2020-07-31T07:19:09.736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe with all required data\n",
    "df = pd.merge(df_orders, df_order_reviews, how=\"inner\",\n",
    "              on=\"order_id\", copy=True)\n",
    "df = df.merge(right=df_customers, how=\"inner\",\n",
    "              on=\"customer_id\", copy=False)\n",
    "# Convert date features into 'datetime' type\n",
    "df[\"review_creation_date\"] = pd.to_datetime(df[\"review_creation_date\"])\n",
    "df[\"review_answer_timestamp\"] = pd.to_datetime(df[\"review_answer_timestamp\"])\n",
    "# Calculate the time to answer in days\n",
    "df[\"review_answer_timedelta\"] = df[\"review_answer_timestamp\"] - df[\"review_creation_date\"]\n",
    "df[\"review_answer_timedelta\"] /= pd.to_timedelta(1, unit=\"D\")\n",
    "\n",
    "values = [\"order_id\",\n",
    "          \"review_id\",\n",
    "          \"review_score\",\n",
    "          \"review_answer_timedelta\"]\n",
    "aggfunc = {\"order_id\": pd.Series.nunique,\n",
    "           \"review_id\": 'count',\n",
    "           \"review_score\": 'mean',\n",
    "           \"review_answer_timedelta\": 'mean'}\n",
    "\n",
    "pivot_reviews = (pd.pivot_table(df, index=\"customer_unique_id\",\n",
    "                               values=values, aggfunc=aggfunc)\n",
    "                  .rename(columns={\"order_id\": \"n_orders\",\n",
    "                                   \"review_id\": \"order_n_reviews\"})\n",
    "                  .assign(order_n_reviews=lambda df: df[\"order_n_reviews\"]/df[\"n_orders\"])\n",
    "                  .drop(columns=[\"n_orders\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T07:19:13.325229Z",
     "start_time": "2020-07-31T07:19:09.738Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moyens de paiement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il pourrait être utile de voir le moyen de paiement privilégié par chaque client. Pour cela nous allons créer une variable par moyen de paiement possible, et nous renseignerons la proportion du montant total payé par ce moyen de paiement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T17:05:10.065779Z",
     "start_time": "2020-08-03T17:05:10.060149Z"
    }
   },
   "outputs": [],
   "source": [
    "def payment_type(data):\n",
    "    \"\"\"Function to get the type of payment used by each customer.\n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "        the pandas object holding data\n",
    "    -----------\n",
    "    Return: 1d Array\n",
    "        the numpy object holding data\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    # Create a feature by type of payment\n",
    "    list_payment_type = (df.payment_type\n",
    "                           .fillna(\"not_defined\")\n",
    "                           .unique()\n",
    "                           .tolist())\n",
    "    list_payment_type.remove(\"not_defined\")\n",
    "    for c in list_payment_type:\n",
    "        cond = df[\"payment_type\"]==c\n",
    "        df[c] = df[\"payment_value\"]\n",
    "        df[c] = df[c].where(cond, 0)\n",
    "    # Group all data by customer\n",
    "    df = df.groupby(\"customer_unique_id\")[list_payment_type].sum()\n",
    "    # Calculate the proportions\n",
    "    for c in list_payment_type:\n",
    "        df[c] /= (data.groupby(\"customer_unique_id\")\n",
    "                      .payment_value\n",
    "                      .sum())\n",
    "    # Impute missing date and normalize data\n",
    "    X = df.fillna(0).values\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    # Realize the PCA\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(X_scaled)\n",
    "    print(\"The percentage of variance explained by the first component is:\\n \\\n",
    "          {}\".format(pca.explained_variance_ratio_))\n",
    "    print(list_payment_type)\n",
    "    print(\"The components of the first component in the feature space are:\\n \\\n",
    "          {}\".format(pca.components_))\n",
    "    return pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T17:05:11.629420Z",
     "start_time": "2020-08-03T17:05:11.005015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of variance explained by the first component is:\n",
      "           [0.47987791]\n",
      "['credit_card', 'debit_card', 'voucher', 'boleto']\n",
      "The components of the first component in the feature space are:\n",
      "           [[-0.71847103  0.12480181  0.14946252  0.6677461 ]]\n"
     ]
    }
   ],
   "source": [
    "data[\"payment_type\"] = payment_type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T16:57:33.962490Z",
     "start_time": "2020-08-03T16:57:33.921547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Monetary_value</th>\n",
       "      <th>order_n_products</th>\n",
       "      <th>type_product</th>\n",
       "      <th>product_category</th>\n",
       "      <th>payment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96096.000000</td>\n",
       "      <td>96096.000000</td>\n",
       "      <td>96096.000000</td>\n",
       "      <td>96096.000000</td>\n",
       "      <td>9.609600e+04</td>\n",
       "      <td>9.609600e+04</td>\n",
       "      <td>9.609600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.853012</td>\n",
       "      <td>1.034736</td>\n",
       "      <td>5.491363</td>\n",
       "      <td>1.183791</td>\n",
       "      <td>-9.760202e-18</td>\n",
       "      <td>3.556559e-17</td>\n",
       "      <td>-4.321847e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.385364</td>\n",
       "      <td>0.210106</td>\n",
       "      <td>2.870511</td>\n",
       "      <td>0.718925</td>\n",
       "      <td>1.237657e+00</td>\n",
       "      <td>1.030330e+00</td>\n",
       "      <td>1.385472e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.585162e+00</td>\n",
       "      <td>-6.750946e+00</td>\n",
       "      <td>-7.916147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-6.920822e-01</td>\n",
       "      <td>-5.452975e-01</td>\n",
       "      <td>-7.916147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.021099e-01</td>\n",
       "      <td>-2.848700e-01</td>\n",
       "      <td>-7.916147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.736730e-01</td>\n",
       "      <td>7.107777e-01</td>\n",
       "      <td>8.497618e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>3.194581e+01</td>\n",
       "      <td>7.539464e+00</td>\n",
       "      <td>2.572321e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Recency     Frequency  Monetary_value  order_n_products  \\\n",
       "count  96096.000000  96096.000000    96096.000000      96096.000000   \n",
       "mean       2.853012      1.034736        5.491363          1.183791   \n",
       "std        2.385364      0.210106        2.870511          0.718925   \n",
       "min        1.000000      1.000000        1.000000          0.000000   \n",
       "25%        1.000000      1.000000        3.000000          1.000000   \n",
       "50%        1.000000      1.000000        5.000000          1.000000   \n",
       "75%        5.000000      1.000000        8.000000          1.000000   \n",
       "max       10.000000     10.000000       10.000000         38.000000   \n",
       "\n",
       "       type_product  product_category  payment_type  \n",
       "count  9.609600e+04      9.609600e+04  9.609600e+04  \n",
       "mean  -9.760202e-18      3.556559e-17 -4.321847e-17  \n",
       "std    1.237657e+00      1.030330e+00  1.385472e+00  \n",
       "min   -1.585162e+00     -6.750946e+00 -7.916147e-01  \n",
       "25%   -6.920822e-01     -5.452975e-01 -7.916147e-01  \n",
       "50%   -3.021099e-01     -2.848700e-01 -7.916147e-01  \n",
       "75%    2.736730e-01      7.107777e-01  8.497618e-02  \n",
       "max    3.194581e+01      7.539464e+00  2.572321e+00  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T07:19:13.332090Z",
     "start_time": "2020-07-31T07:19:09.750Z"
    }
   },
   "outputs": [],
   "source": [
    "# export in csv format the cleaned/transformed datasets\n",
    "data.to_csv(\"data/data_cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
